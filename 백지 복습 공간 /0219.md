# Day5

### OLAP OLTP

이 둘은 전부 정보를 프로세싱하는 기법임. OLTP는 일반 IT 서비스의 데이터베이스 처리과정을 생각하면 될 것 같고, OLAP는 분석에 초점을 맞춘 프로세싱임. 

OLAP는 결국 정규화된 테이블을 비정규화시켜서 크로스 집계하는 구조라고 보면 됨.

데이터베이스는 일반적으로 `트랜잭션`, `마스터`로 테이블을 구분할 수 있음. 트랜잭션에 중요한 수치들이 들어가며, 마스터에는 트랜잭션이 참고하는 메타데이터들이 들어간다고 보면 됨. (일반적인 RDB의 RM이 이런 구조)

### 데이터 웨어하우스

데이터웨어하우스의 테이블을 나누면 크게 `팩트 테이블`과 `디멘전 테이블`이 있다. 팩트 테이블은 트랜잭션 처럼 주요 사실들이 들어간 공간이며 디멘전 테이블은 마스터 처럼 참고되는 공간이다.

데이터 마트나 데이터 웨어하우스같이 대용량 데이터 저장소의 스키마를 설계할 때 `스타 스키마`와 `스노우플레이크 스키마`로 나뉜다. 팩트 테이블을 중심으로 하되 스타는 디멘전이 크게 정규화되지 않은 구조이며, 스노우플레이크는 디멘전도 세밀하게 정규화된 구조다

데이터 웨어하우스는 스타 스키마 구조를 지향하는 게 좋다고 한다.

### 데이터마트

**데이터 마트는 스타 스키마 구조보다는 아예 `비정규화` 시키는 것이 크로스집계에는 유리하다고 함.** 요새는 데이터 마트를 열지향으로 하기에 컬럼이 늘어나도 성능에 영향을 안끼침. 그래서 **비정규화로 컬럼들이 많이 늘어나도 문제가 없으며 크로스 집계 하기도 용이할 거임.**

비정규화 테이블을 꼭 몽고디비같은 schemaless로만 생각하지 말기. 

### 다차원모델

![Day5%20278e27f741ef4ef792c17d273b1bde33/Untitled.png](Day5%20278e27f741ef4ef792c17d273b1bde33/Untitled.png)

일반적으로 OLAP에서는 크로스 집계가 일어나므로 차원이라는 것이 존재함. 일반 RDB구조와는 다르다는 이야기

기본적으로 `다차원 모델` 이라고 부르며 다차원 모델의 칼럼은 `디멘전`, `측정값` 으로 나뉘며, 디멘전들이 교차한는 공간에 측정값이 들어간다고 보면 됨.

### 애드혹

애드 혹의 경우 비싼 BI 툴보다는 주피터 같은 REPL(Read-Eval-Print-Loop) 툴이 나은듯 ㅎ

### 동시성

동시성은 concurrent하게, 즉 완전히 병렬적으로 수행되는게 아니라 한 코어에서 왔다갔다하면서 동시에 여러가지 하는 형태를 의미함

### stack

stack은 누적된다. 그리고 `과거를 쫓아`간다. 과거를 쫓아가서 비교할 때 stack을 써라. 

### DFS BFS

dfs는 깊이 탐구, dfs는 일반적으로 모든 경로를 탐색할때 사용함.

 bfs는 너비 탐구. bfs는 다익스트라로 최소 경로를 측정할 때 사용함

### 백트래킹

백트래킹은 DFS의 골격을 이루는 알고리즘이라고 보면 되는데, 만약에 없으면 돌아가고, 다시 들어가는 걸 반복하는 작업임

### 재귀함수

기본적으로 for문으로 구현하는 작업을 더 우아하게 할 수 있음. 함수 안에 재귀가 호출되는 부분 상위 코드는 차례대로 축적된다고 보면 되며 아래 코드는 Stack이 pop되듯이 끝에서부터 터진다고 보면 됨.

재귀함수를 진짜 다양한 패턴으로 연습해봐야 됨. dfs에서 많이 사용되는 편인데, 여러 패턴으로 사용이 가능하므로 익혀두는 게 좋을 듯

### 이차배열 포인터 문제

이차배열에서는 기본적으로 한 번 베껴내더라도 배열이다. 근데 여기서 문제는 배열이 mutable이므로 값을 변경하는 작업들이 있다면 copy를 해주는 게 좋음. deepcopy나 [:]를 사용하기 

### 중첩함수

중첩함수는 상위 함수의 객체를 그대로 사용할 수 있다는 장점이 있음. 다만 mutable 객체를 변경하려고 하면 변경이 되지 않고 새로운 변수가 중첩 함수 안에 생성이 된다. 

### 객체참조

파이썬은 항상 변수가 객체를 참조함. 그래서 값을 바꾼다는 건 객체가 바뀌는 걸 뜻함. 기존 객체는 그대로 남아있음. LinkedList에서도 헷갈렸었는데 객체는 항상 남아있다는 게 핵심임. 알고리즘 풀 때도 객체 참조 때문에 (특히 mutable) 값을 바꾸는 실수를 하지 말자

### 순열, 조합

순열인 경우 값들을 전부 조회하면 되기에 간단하게 순회하면서 배열 값을 추가하면 된다. 

다만 조합인 경우 `순서`가 생긴다. 그래서 순서를 유지할 수 있도록 함수 안에서 반복적으로 순회할 배열들을 조절해줘야 한다.

```python
def dfs(elements,start) :
 for i in range(start:n+1):
	dfs(...,start+1)
...
dfs(arr, i)
```

### HDFS 리소스매니저 & 분산 애플리케이션

HDFS는 분산 파일 시스템으로 말그대로 파일들을 저장하는 공간임. S3 같이 파일 스토리지 역할을 한다고 보면 됨

YARN은 Hadoop에서 자원을 관리해주는 리소스 매니저로 CPU 코어와 메모리를 할당해서 분산 처리를 진행하도록 돕는다.

고인 mapreduce는 yarn 매니징을 통해서 동작하는 분산 처리 애플리케이션임. 

### 쿼리엔진 ( Hive & Presto & Spark )

Hive는 기존에 MapReduce 작업을 더 high level management로 할 수 있는 (SQL 사용 가능) `쿼리 엔진`이라고 보면 된다. 

Hive는 대용량 데이터를 처리할 때 디스크에서 데이터를 읽으며 높은 Throughput으로 처리한다고 함. 그러나 저용량 데이터들을 처리하기에는 성능이 아쉬움. 그래서 나온게 Presto. presto는 기본적으로 대화형 쿼리 엔진이며 SQL 표준을 따른다고 해서 비개발자들도 충분히 쓸 수 있음. 또 다양한 플러그인을 해줘서 좋은듯?. spark와 비슷하게 인메모리로 데이터를 처리하기에 속도가 빠르다. 실행계획을 세우는 것까지 비슷

Spark는 MR보다 더 효율적인 데이터 처리가 가능함. 메모리 처리를 통해 속도가 빠르고 실행 계획을 세울 수 있어  최적의 방법으로 데이터 처리를 수행함.

### 쿼리 엔진(Hive, Presto) 동작 흐름

비구조화, 스키마리스 데이터를 쿼리엔진을 통해서 구조화하는 작업이 들어감. 이 과정에서 팩트 테이블과 마스터 테이블이 생성이 됨. 팩트 테이블이 메인, 디멘전 테이블은 서브라고 보면 됨. 보통 구조화 작업은 시간이 많이 걸려 Hive를 사용함. 그리고 구조화된 데이터를 집약해서(다시 비구조화) 데이터 마트로 보내는 작업을 할 때는 Presto를 사용한다고 함. 

### 서브쿼리 최적화

보통 JOIN을 할 때 자원을 많이 먹음. 그래서 처음부터 JOIN할 데이터를 줄여놓으면 시간을 단축시킬 수 있음. 

```sql
select ... from (
	--필요한 것만 미리 뽑기--
	select .. from ..
) a
join on ...
```

### 데이터 편향

분산처리에 최적화되기 위해선 데이터 편향을 피해야 함. 분산처리하는 컴퓨팅 자원은 동일한데 한쪽이 오래걸리면 결국 병렬처리이기에 병목이 발생함. 그래서 고르게 데이터를 분산해줘야 함

예를 들어 `group by` 에 의한 그룹화한 후에는 분산처리가 가능함. 1일부터 30일 데이터를 그루핑한다면 30개까지 분산처리가 가능함. 근데 데이터가 편향되면.. 곤란. 그래서 처음부터 데이터 카디널리티(중복도)를 낮추면 좋음. IP 주소를 국가나 지역으로 바꾸거나 이런 작업들이 들어가면 더 성능이 개선될 듯